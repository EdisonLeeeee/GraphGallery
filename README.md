<a class="toc" id="table-of-contents"></a>
# Table of Contents
+ [GraphGallery](#1)
+ [Requirements](#2)
+ [Usage](#3)
	+ [Inputs](#3-1)
	+ [GCN](#3-2)
	+ [DenseGCN](#3-3)
	+ [EdgeGCN](#3-4)
	+ [GDC](#3-5)
	+ [ChebyNet](#3-6)
	+ [FastGCN](#3-7)
	+ [GraphSAGE](#3-8)
	+ [RobustGCN](#3-9)
	+ [SGC](#3-10)
	+ [GWNN](#3-11)
	+ [GAT](#3-12)
	+ [ClusterGCN](#3-13)
	+ [SBVAT](#3-14)
	+ [OBVAT](#3-15)
	+ [GMNN](#3-16)
	+ [LGCN](#3-17)
	+ [Deepwalk](#3-18)
	+ [Node2vec](#3-19)


<a class="toc" id ="1"></a>
# GraphGallery
[ðŸ”™](#table-of-contents)

A gallery of state-of-the-arts graph neural networks.. 

Implemented with Tensorflow 2.x.

This repo aims to achieve 4 goals:
+ Similar (or higher) performance with the corresponding papers
+ Faster implementation of training and testing
+ Simple and convenient to use, high scalability
+ Easy to read source codes

<a class="toc" id ="2"></a>
# Requirements
[ðŸ”™](#table-of-contents)

+ python>=3.7
+ tensorflow>=2.1 (2.1 is recommended)
+ networkx==2.3
+ scipy>=1.4.1
+ sklearn>=0.22
+ numpy>=1.18.1
+ numba>=0.48
+ gensim>=3.8.1

Extral packages (not necessaryï¼‰:

+ metis==0.2a4
+ texttable

To install **metis**, jus type:
```bash
sudo apt-get install libmetis-dev 
pip install metis
```

To install **texttable**, just type:

```bash
pip install texttable
```

<a class="toc" id ="3"></a>

# Usage
[ðŸ”™](#table-of-contents)

<a class="toc" id ="3-1"></a>
## Inputs
[ðŸ”™](#table-of-contents)

### Init

+ adj: shape (N, N), `scipy.sparse.csr_matrix` (or `csc_matrix`) if  `is_adj_sparse=True`, `np.array` or `np.matrix` if `is_adj_sparse=False`.
  
    â€‹      The input  symmetric adjacency matrix, where `N` is the number of nodes in graph.
    
+  x: shape (N, F), `scipy.sparse.csr_matrix` (or `csc_matrix`) if  `is_x_sparse=True`, `np.array` or `np.matrix` if `is_x_sparse=False`.

    â€‹      The input node feature matrix, where `F` is the dimension of features.

+ labels: shape (N,), array-like. Default: `None` for unsupervised learning.

    â€‹      The class labels of the nodes in the graph. 

+ device: string. Default: `CPU:0`.

    â€‹      The device where the model running on.

+ seed: interger scalar. Default: `None`.

    â€‹      Used in combination with `tf.random.set_seed` & `np.random.seed` & `random.seed` 

    â€‹      to create a reproducible sequence of tensors across multiple calls. 

+ name: string. Default: `None` which will be the name of the classes. 

    â€‹      Specified name for the model.  (default: `class.__name__`)

### Training

+ idx_train: `np.array`, `list`, Integer scalar or `graphgallery.NodeSequence`
  the index of nodes (or sequence) that will be used during training.    
+ idx_val: `np.array`, `list`, Integer scalar or `graphgallery, optional.NodeSequence`
  the index of nodes (or sequence) that will be used for validation. 
  (default :obj: `None`, i.e., do not use validation during training)
+ idx_test: `np.array`, `list`, Integer scalar or `graphgallery.NodeSequence`
  The index of nodes (or sequence) that will be tested.   

You can specified customized hyperparameters and training details by calling `model.build(your_args)` and `model.trian(your_args)`. 
The usuage documents will be gradually added later.

<a class="toc" id ="3-2"></a>
## GCN
[ðŸ”™](#table-of-contents)

+ [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907), ICLR 2017
+ Tensorflow 1.x implementation: https://github.com/tkipf/gcn
+ Pytorch implementation: https://github.com/tkipf/pygcn

```python
from graphgallery.nn.models import GCN
model = GCN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```


<a class="toc" id ="3-3"></a>
## DenseGCN
[ðŸ”™](#table-of-contents)

Dense version of `GCN`, i.e., the `adj` will be transformed to `Tensor` instead of `SparseTensor`.

```python
from graphgallery.nn.models import DenseGCN
model = DenseGCN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-4"></a>
## EdgeGCN
[ðŸ”™](#table-of-contents)

Edge Convolutional version of `GCN`, using message passing framework,
i.e., using Tensor `edge index` and `edge weight` of adjacency matrix to aggregate neighbors'
message, instead of SparseTensor `adj`.

Inspired by: tf_geometric and torch_geometric
+ tf_geometric: https://github.com/CrawlScript/tf_geometric
+ torch_geometric: https://github.com/rusty1s/pytorch_geometric

```python
from graphgallery.nn.models import EdgeGCN
model = EdgeGCN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-5"></a>
## GDC
[ðŸ”™](#table-of-contents)

+ [Diffusion Improves Graph Learning](https://arxiv.org/abs/1911.05485), NeurIPS 2019
+ official implementation: https://github.com/klicperajo/gdc
+ torch_geometric implementation: https://github.com/rusty1s/pytorch_geometric/blob/master/torch_geometric/transforms/gdc.py


```python
from graphgallery.nn.models import GCN
from graphgallery.utils import GDC

GDC_adj = GDC(adj, alpha=0.3, k=128, which='PPR')
model = GCN(GDC_adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-6"></a>
## ChebyNet
[ðŸ”™](#table-of-contents)

+ [Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering](https://arxiv.org/abs/1606.09375), NeurIPS 2016
+ Tensorflow 1.x implementation: https://github.com/mdeff/cnn_graph, https://github.com/tkipf/gcn
+ Keras implementation: https://github.com/aclyde11/ChebyGCN

```python
from graphgallery.nn.models import ChebyNet
model = ChebyNet(adj, x, labels, order=2, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-7"></a>
## FastGCN
[ðŸ”™](#table-of-contents)

+ [FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling](https://arxiv.org/abs/1801.10247), ICLR 2018
+ Tensorflow 1.x implementation: https://github.com/matenure/FastGCN

```python
from graphgallery.nn.models import FastGCN
model = FastGCN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-8"></a>
## GraphSAGE
[ðŸ”™](#table-of-contents)

+ [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216), NeurIPS 2017
+ Tensorflow 1.x implementation: https://github.com/williamleif/GraphSAGE
+ Pytorch implementation: https://github.com/williamleif/graphsage-simple/

```python
from graphgallery.nn.models import GraphSAGE
model = GraphSAGE(adj, x, labels, n_samples=[10, 5], device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100, save_best=False, validation=False)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-9"></a>
## RobustGCN
[ðŸ”™](#table-of-contents)

+ [Robust Graph Convolutional Networks Against Adversarial Attacks](https://dl.acm.org/doi/10.1145/3292500.3330851), KDD 2019
+ Tensorflow 1.x implementation: https://github.com/thumanlab/nrlweb/blob/master/static/assets/download/RGCN.zip

```python
from graphgallery.nn.models import RobustGCN
model = RobustGCN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-10"></a>
## SGC
[ðŸ”™](#table-of-contents)

+ [Simplifying Graph Convolutional Networks](https://arxiv.org/abs/1902.07153), ICML 2019
+ Pytorch implementation: https://github.com/Tiiiger/SGC
        
```python
from graphgallery.nn.models import SGC
model = SGC(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-11"></a>
## GWNN
[ðŸ”™](#table-of-contents)

+ [Graph Wavelet Neural Network](https://arxiv.org/abs/1904.07785), ICLR 2019
+ Tensorflow 1.x implementation: https://github.com/Eilene/GWNN
+ Pytorch implementation: https://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork
        
```python
from graphgallery.nn.models import GWNN
model = GWNN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-12"></a>
## GAT
[ðŸ”™](#table-of-contents)

+ [Graph Attention Networks](https://arxiv.org/abs/1710.10903), ICLR 2018
+ Tensorflow 1.x implementation: https://github.com/PetarV-/GAT
+ Pytorch implementation: https://github.com/Diego999/pyGAT
+ Keras implementation: https://github.com/danielegrattarola/keras-gat
        
```python
from graphgallery.nn.models import GAT
model = GAT(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=200)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-13"></a>
## ClusterGCN
[ðŸ”™](#table-of-contents)

+ [Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks](https://arxiv.org/abs/1905.07953), KDD 2019
+ Tensorflow 1.x implementation: https://github.com/google-research/google-research/tree/master/cluster_gcn
+ Pytorch implementation: https://github.com/benedekrozemberczki/ClusterGCN

```python
from graphgallery.nn.models import ClusterGCN
model = ClusterGCN(adj, x, labels, n_cluster=10, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-14"></a>
## SBVAT
[ðŸ”™](#table-of-contents)

+ [Batch Virtual Adversarial Training for Graph Convolutional Networks](https://arxiv.org/abs/1902.09192), ICML 2019
+ Tensorflow 1.x implementation: https://github.com/thudzj/BVAT

```python
from graphgallery.nn.models import SBVAT
model = GMNN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```


<a class="toc" id ="3-15"></a>
## OBVAT
[ðŸ”™](#table-of-contents)

+ [Batch Virtual Adversarial Training for Graph Convolutional Networks](https://arxiv.org/abs/1902.09192), ICML 2019
+ Tensorflow 1.x implementation: https://github.com/thudzj/BVAT

```python
from graphgallery.nn.models import OBVAT
model = OBVAT(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```


<a class="toc" id ="3-16"></a>
## GMNN
[ðŸ”™](#table-of-contents)

+ [Graph Markov Neural Networks](https://arxiv.org/abs/1905.06214), ICML 2019
+ Pytorch implementation: https://github.com/DeepGraphLearning/GMNN


```python
from graphgallery.nn.models import GMNN
model = GMNN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-17"></a>

## LGCN
[ðŸ”™](#table-of-contents)

+ [Large-Scale Learnable Graph Convolutional Networks](https://arxiv.org/abs/1808.03965), KDD 2018
+ Tensorflow 1.x implementation: https://github.com/divelab/lgcn

```python
from graphgallery.nn.models import LGCN
model = GMNN(adj, x, labels, device='CPU', seed=123)
model.build()
his = model.train(idx_train, idx_val, verbose=True, epochs=100)
loss, accuracy = model.test(idx_test)
model.close # clear session
print(f'Test loss {loss:.5}, Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-18"></a>

## Deepwalk
[ðŸ”™](#table-of-contents)

+ [DeepWalk: Online Learning of Social Representations](https://arxiv.org/abs/1403.6652), KDD 2014
+ Implementation: https://github.com/phanein/deepwalk

```python
from graphgallery.nn.models import Deepwalk
model = Deepwalk(adj, x, labels)
model.build()
model.train(idx_train)
accuracy = model.test(idx_test)
print(f'Test accuracy {accuracy:.2%}')
```

<a class="toc" id ="3-19"></a>
## Node2vec
[ðŸ”™](#table-of-contents)

+ [node2vec: Scalable Feature Learning for Networks](https://arxiv.org/abs/1607.00653), KDD 2016
+ Implementation: https://github.com/aditya-grover/node2vec
+ Cpp implementation: https://github.com/snap-stanford/snap/tree/master/examples/node2vec

```python
from graphgallery.nn.models import Node2vec
model = Node2vec(adj, x, labels)
model.build()
model.train(idx_train)
accuracy = model.test(idx_test)
print(f'Test accuracy {accuracy:.2%}')
```
